<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Elasticsearch-实践篇]]></title>
      <url>/2018/01/29/Elasticsearch-%E5%AE%9E%E8%B7%B5%E7%AF%87/</url>
      <content type="html"><![CDATA[<h2 id="Elasticsearch实践"><a href="#Elasticsearch实践" class="headerlink" title="Elasticsearch实践"></a>Elasticsearch实践</h2><p>前两篇文章初步介绍了Elasticsearch的基础和索引，因此第三篇我决定写一下如何利用Elasticsearch来搭建一个搜索服务以及工作中常用的维护手段。</p>
<p><strong>注：由于条件有限，本次介绍的是单机部署，没有用到分布式部署，后续会在这篇文章中更新分布式部署细节。</strong></p>
<h2 id="Linux下安装和部署"><a href="#Linux下安装和部署" class="headerlink" title="Linux下安装和部署"></a>Linux下安装和部署</h2><h3 id="1-下载安装"><a href="#1-下载安装" class="headerlink" title="1 下载安装"></a>1 下载安装</h3><ul>
<li><p>大家可以从<a href="https://www.elastic.co/cn/" target="_blank" rel="noopener">官网</a>下载es的压缩包，也可以通过其他渠道获取相关资源，比如我是从官网下载的<code>elasticsearch-5.6.7.tar.gz</code>压缩包。</p>
</li>
<li><p>解压：<code>tar -zxvf elasticsearch-5.6.7.tar.gz</code></p>
</li>
<li><p>运行es：<code>./bin/elasticsearch</code> 如果需要后台运行，执行<code>./bin/elasticsearch -d</code> </p>
<p>  启动es的时候可能会出现如下错误</p>
<blockquote>
<p>No Java runtime present, requesting install. Elasticsearch requires at least Java 8 but your Java version from /usr/bin/java does not meet this requirement</p>
</blockquote>
<p> <img src="/img/20180131/log2018013100.png" alt=""></p>
<p>  相关问题错误信息已经描述很清楚了，毕竟es是用Java写的，因此需要安装Java环境并不过分对吧哈哈哈。Java环境安装就不在这里记录了，我用的是Mac，利用强大的homebrew工具分分钟解决。</p>
<p>  安装好Java环境之后，重新启动es，如果不是后台运行，出现如下信息就代表成功了,</p>
<p> <img src="/img/20180131/log2018013101.png" alt=""></p>
<p>  如果是后台运行，<code>ps -ef | grep &#39;elas&#39;</code>看一下进程是否启动即可，如下</p>
<p> <img src="/img/20180131/log2018013103.png" alt=""></p>
</li>
<li><p>测试： 在浏览器中输入<code>http://localhost:9200/</code>，出现如下信息就代表es已经正常运行了</p>
<p> <img src="/img/20180131/log2018013102.png" alt=""> </p>
</li>
</ul>
<h3 id="2-创建数据"><a href="#2-创建数据" class="headerlink" title="2 创建数据"></a>2 创建数据</h3><pre><code>在基础篇中我们提到了，es提供了restful api接口来让我们很方便的操作数据，因此我们后续所有相关操作都会直接用curl发http请求来完成。
</code></pre><ul>
<li><p>创建索引：<code>curl -XPUT &#39;127.0.0.1:9200/index_v1&#39;</code>，创建完成之后可以查看一下创建的索引信息 <code>curl -XGET &#39;127.0.0.1:9200/index_v1?pretty&#39;</code>，加pretty是格式化返回结果，更直观。</p>
<p> <img src="/img/20180131/log2018013104.png" alt=""> </p>
<p>  返回结果包括三个核心信息：aliases（别名）、mappings（映射）、settings（配置），具体三个字段代表的信息可以从文档中搜索到。简单来说aliases是给这个索引加一个别名，这样可以通过别名来获取这个索引相关信息，这个在工程中是很好用的，重建索引的时候就需要利用别名的特性。mapping是和后面讲到的type类型相关，存储了字段属性信息。settings中有很多信息，这些是es默认加上的属性，具体也建议看一下es文档。</p>
</li>
<li><p>创建类型：索引相当于数据库，类型相当于表，在创建类型的时候需要设计好字段属性，也就是mapping，类型和映射往往是一起存在的。<br><code>curl -XPOST &#39;127.0.0.1:9200/index_v1/default/_mapping?pretty&#39; -d &#39;{&quot;default&quot;:{&quot;properties&quot;:{&quot;id&quot;:{&quot;type&quot;:&quot;string&quot;, &quot;index&quot;:&quot;not_analyzed&quot;}, &quot;name&quot;:{&quot;type&quot;:&quot;string&quot;, &quot;index&quot;:&quot;not_analyzed&quot;}}}}&#39;</code></p>
<p> <img src="/img/20180131/log2018013105.png" alt=""></p>
<p>  type表示该字段类型，index中定义not_analyzed是表示该字段不分词，分词是搜索引擎中一个很重要的概念，有兴趣可以查资料深入研究下。</p>
</li>
<li><p>写入数据：索引和类型都ready之后，就可以往es中写入应用数据了。应用中，可能数据源来自多个地方，可能每一份数据都不一样，不管源数据是什么样，我们都需要通过某种手段将数据格式化之后灌入es。灌es方式也有很多，往往是离线和在线相结合。这里我们只是通过最简单的http请求来写入数据。</p>
<p> 我们创建了一个default类型，定义了两个字段id和name，写入数据可以这样：<code>curl -XPUT &#39;127.0.0.1:9200/index_v1/default/d123&#39; -d &#39;{&quot;id&quot;:&quot;d123&quot;,&quot;name&quot;:&quot;liuwei&quot;}&#39;</code>，和mysql类似，es也需要定义一个唯一标识id，工程中我们经常根据数据特征选取唯一标识。比如，这个示例中，我们将id作为唯一标识，执行之后会得到如下结果，如果需要格式化，加上<strong>?pretty</strong>即可。</p>
<p><img src="/img/20180131/log2018013106.png" alt=""></p>
<p> 工作中我们经常会利用脚本来批量更新es数据，感兴趣的同学可以看看python的es包，或者也可以利用es本身的bulk api来批量操作数据，但是总体来说利用python多线程加es bulk在实际工作中显得更加方便。</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> 开源技术 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch-索引篇]]></title>
      <url>/2018/01/12/Elasticsearch-%E7%B4%A2%E5%BC%95%E7%AF%87/</url>
      <content type="html"><![CDATA[<h2 id="Elasticsearch索引原理"><a href="#Elasticsearch索引原理" class="headerlink" title="Elasticsearch索引原理"></a>Elasticsearch索引原理</h2><p>Elasticsearch的核心是搜索，为了最大化搜索的性能，Elasticsearch内部采用了倒排索引的思路。当然，万物相生相克，在搜索性能提升的同时，无法避免会增加更新等操作的成本，对于Elasticsearch来说是可以的。</p>
<h2 id="什么是倒排索引"><a href="#什么是倒排索引" class="headerlink" title="什么是倒排索引"></a>什么是倒排索引</h2><blockquote>
<p>In computer science, an inverted index (also referred to as postings file or inverted file) is an index data structure storing a mapping from content, such as words or numbers, to its locations in a database file, or in a document or a set of documents (named in contrast to a forward index, which maps from documents to content). The purpose of an inverted index is to allow fast full text searches, at a cost of increased processing when a document is added to the database. </p>
<p>倒排索引（英语：Inverted Index），也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。 它是文档检索系统中最常用的数据结构。</p>
</blockquote>
<p>这是维基百科上面的一句话。不管什么场合，中英互译在科学界总是会存在很多争议，但是基本我们习惯了用倒排索引来称呼Inverted Index。从这句描述中，我们需要记住“存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射”，我们从实际数据角度来理解这句话，也就理解了倒排索引的概念。</p>
<h3 id="倒排索引实例"><a href="#倒排索引实例" class="headerlink" title="倒排索引实例"></a>倒排索引实例</h3><p>假如现在有五个文档，如下表所示</p>
<table>
<thead>
<tr>
<th>文档id</th>
<th>文档内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>亚当喜欢吃苹果 </td>
</tr>
<tr>
<td>2</td>
<td>亚当和夏娃的故事</td>
</tr>
<tr>
<td>3</td>
<td>苹果电脑厉害  </td>
</tr>
<tr>
<td>4</td>
<td>乔布斯喜欢苹果</td>
</tr>
</tbody>
</table>
<p>文档ID作为一个文档的唯一标识，一般来说是我知道文档ID才能知道找到文档，但是在搜索场景中，需求肯定是我想知道哪些文档有亚当这个关键词，这个时候就需要一个文档内容到文档ID的映射关系，这个映射关系我们可以认为是一种倒排索引的数据结构。</p>
<p>按照这种思路，我们可以得到这样一份数据，（这里会涉及一个分词的逻辑，暂时不介绍，可以google或者百度查一下），当然我们也可以处理成更加详细的数据，记录每个关键词在文档中的位置以及出现的频率等，实际中lucene也是这样做的，这里我们尽量用最简单的情况介绍即可</p>
<table>
<thead>
<tr>
<th>关键词</th>
<th>文档id</th>
</tr>
</thead>
<tbody>
<tr>
<td>亚当</td>
<td>1，2 </td>
</tr>
<tr>
<td>夏娃</td>
<td>2</td>
</tr>
<tr>
<td>喜欢</td>
<td>1，4</td>
</tr>
<tr>
<td>苹果</td>
<td>1，3，4</td>
</tr>
<tr>
<td>故事</td>
<td>2</td>
</tr>
<tr>
<td>厉害</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>上面我们可以认为文档内容就是es中的一个field，es会为每一个field建立索引，这里的field就相当于mysql里面的列名。那么问题来了，当需要查“亚当”的时候，我如何定位到亚当这条数据呢？</p>
<h3 id="es索引机制"><a href="#es索引机制" class="headerlink" title="es索引机制"></a>es索引机制</h3><p><em>假设现在通过分词，对某个field（假设叫F1）分词处理之后的得到terms集合（假设叫T1）</em></p>
<p><strong>需求：需要搜索F1中出现t1的数据</strong></p>
<p>es会对T1中所有单词排序，二分法查找t1， 这样可以保证logN的时间复杂度，另外这种查找是在内存中直接操作的，没有磁盘IO消耗。难道是所有单词索引都在内存中完成吗，当然这是不现实的。es利用了字典的思路，只会在内存中处理前缀，然后通过前缀定位到该前缀相关的数据在磁盘中的位置，就像我们查字典一样。同时，es也利用了磁盘顺序读写的特点，尽量减少磁盘索引的时间。</p>
<p>也就是我先获取t1的前缀假设是t（每个语言会有特殊的处理，暂时我们可以按照简单清晰的英文思路来处理），然后在内存中根据建立的前缀索引进行二分查找，这样可以获取到t为前缀的索引在磁盘中的位置，然后再去磁盘中定位到t1，再根据t1就能获取到对应的文档id集合了。</p>
<p>看了很多博客资料，下面这幅图就很好描述了这种过程。</p>
<p><img src="/img/20180119/log2018011901.png" alt=""></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>es充分利用了内存，磁盘和压缩等技术来尽可能发挥倒排索引的优势，这也说明他作为搜索引擎的特性。当然不同的场景需要不同的技术，感兴趣的同学可以看看mysql的不同引擎使用的索引（主要是B树结构）。</p>
<h2 id="随便聊聊"><a href="#随便聊聊" class="headerlink" title="随便聊聊"></a>随便聊聊</h2>]]></content>
      
        <categories>
            
            <category> 开源技术 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch-基础篇]]></title>
      <url>/2017/12/17/Elasticsearch-%E5%9F%BA%E7%A1%80%E7%AF%87/</url>
      <content type="html"><![CDATA[<h2 id="为什么要写Elasticsearch？"><a href="#为什么要写Elasticsearch？" class="headerlink" title="为什么要写Elasticsearch？"></a>为什么要写Elasticsearch？</h2><p>我是工作之后开始接触到了搜索相关需求，并且在两个不同的大的业务场景都用到了这个工具Elasticsearch，虽然用的出发点不一样，但是也都能看出这个工具的重要性。我应该会分好几篇来写Elasticsearch，希望可以尽可能从浅到深（^o^如果我的知识储存允许的话哈哈哈）。</p>
<h2 id="基础介绍"><a href="#基础介绍" class="headerlink" title="基础介绍"></a>基础介绍</h2><blockquote>
<p>Elasticsearch 是一个开源的搜索引擎，建立在一个全文搜索引擎库Apache Lucene基础之上。</p>
</blockquote>
<p>这是官方中文文档上面的一句话。分析一下这句话，我们可以发现以下几个关键词：开源、搜索引擎、全文搜索、Apache Lucene库。首先它是开源的，然后它是一个搜索引擎（意思就是它实现了搜索的核心功能，并且通过封装给你提供一个友好的交互接口），全文搜索和Apache Lucene是放一起的，但是这两个分开介绍都是很有意义的。</p>
<h3 id="全文搜索"><a href="#全文搜索" class="headerlink" title="全文搜索"></a>全文搜索</h3><blockquote>
<p>全文检索是指计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。这个过程类似于通过字典中的检索字表查字的过程。</p>
</blockquote>
<p>这是百度百科上面的一句话，基本也清晰的介绍了全文搜索的概念，这个概念对于理解Elasticsearch的实现原理是很重要的，由此也引出来另外一个重要的概念-倒排索引（这个会在一个合适的时机提到）。</p>
<h3 id="Lucene"><a href="#Lucene" class="headerlink" title="Lucene"></a>Lucene</h3><blockquote>
<p>Apache Lucene is a free and open-source information retrieval software library, originally written completely in Java by Doug Cutting. It is supported by the Apache Software Foundation and is released under the Apache Software License.</p>
</blockquote>
<p>这是维基百科（广告：个人很喜欢维基百科，并且其创始人的事迹也是帅爆）上面的介绍， 就不一一分析了，大致上意思就是Lucene是一个叫Doug Cutting的大牛用Java写的一个全文索引引擎工具库，注意它是一个工具库而不是一个应用。</p>
<h3 id="为什么不直接用Lucene呢"><a href="#为什么不直接用Lucene呢" class="headerlink" title="为什么不直接用Lucene呢"></a>为什么不直接用Lucene呢</h3><p>Lucene是一个偏复杂的东西，对使用者来说需要的学习成本偏高，而Elasticsearch内部使用Lucene 做索引与搜索，它的目标是使全文检索变得简单，通过隐藏Lucene的复杂性，取而代之的提供一套简单一致的RESTful API。“开箱即用”的优势让Elasticsearch成为一个明星开源工具。顺便贴一下官方文档上面的附加“简历”：</p>
<ul>
<li>一个分布式的实时文档存储，每个字段 可以被索引与搜索</li>
<li>一个分布式实时分析搜索引擎</li>
<li>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据</li>
</ul>
<p>基本通过上面这些介绍，基本上回答了Elasticsearch是什么，有什么用的问题。</p>
<h2 id="入门介绍"><a href="#入门介绍" class="headerlink" title="入门介绍"></a>入门介绍</h2><p>上面主要从大的背景出发介绍了一下基础点，接下来是从Elasticsearch本身出发介绍一下相关知识点。</p>
<p>我们知道传统的关系数据库（比如mysql）存储的数据是格式化的，负责处理结构化的二维数据。数据的格式化决定了其业务场景的限制，但是也带来了一些优势（比如事务等特性）。但是21世纪的数据已经远远不能用横和列二维结构来表示，为了弥补现在的缺陷，新的技术应运而生，出现了NoSQL以及类似Elasticsearch这种分布式搜索系统，其实从某种程度上也可以把Elasticsearch当作NoSQL来用。</p>
<h3 id="面向文档"><a href="#面向文档" class="headerlink" title="面向文档"></a>面向文档</h3><blockquote>
<p>Elasticsearch是面向文档的，意味着它存储整个对象或文档。Elasticsearch不仅存储文档，而且索引每个文档的内容使之可以被检索。在Elasticsearch中，你对文档进行索引、检索、排序和过滤，而不是对行列数据。这是一种完全不同的思考数据的方式，也是Elasticsearch能支持复杂全文检索的原因。</p>
<p>Elasticsearch使用json描述语言来序列化文档。</p>
</blockquote>
<p>如果上面的官方描述比较抽象的话，我们可以和熟悉的mysql做一个对比。Mysql中我们最熟悉的结构是库-表-行-列，在Elasticsearch中，我们可以把关系数据库的概念移植过来，这样会很好理解其交互逻辑。</p>
<table>
<thead>
<tr>
<th>Mysql</th>
<th>Elasticsearch</th>
</tr>
</thead>
<tbody>
<tr>
<td>库（database）</td>
<td>索引（index） </td>
</tr>
<tr>
<td>表（table）</td>
<td>类型（type）</td>
</tr>
<tr>
<td>行（rows）</td>
<td>文档（document）  </td>
</tr>
<tr>
<td>列（columns）</td>
<td>字段（field）</td>
</tr>
</tbody>
</table>
<p>我们可以看到在关系数据库中，一个行就是一条数据，对应在Elasticsearch，一个文档也就是一条数据。毕竟都是实现检索的功能，概念上面殊途同归也没什么问题。</p>
<h3 id="Restful-Api接口"><a href="#Restful-Api接口" class="headerlink" title="Restful Api接口"></a>Restful Api接口</h3><p>Elasticsearch提供Restful Api接口来操作数据，一个url即可表示一个资源，用户用http的标准方法（POST、DELETE、GET、PUT）即可实现相应的增删查改逻辑。</p>
<p>比如我们的服务搭建在127.0.0.1:9000，创建了一个index_a索引，然后创建了一个type_a类型，然后我们即可通过POST操作向127.0.0.1:9000/index_a/type_a中添加一个文档document_a，然后通过GET操作127.0.0.1:9000/index_a/type_a/document_a即可取到我们添加的数据，PUT和DELETE也是一样的逻辑。</p>
<p>对用户来讲，一个基于Restful Api的服务和一个基于json的数据实在是简单的不能再简单了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这一篇简要介绍了Elasticsearch的基础概念，希望可以在看完之后大家能对Elasticsearch有一个大致的印象，当然更加详细的内容大家可以在我提供的参考资料里面去了解一下。下一篇我将介绍一下Elasticsearch的索引原理（主要是倒排索引），这也是一个很关键的理解点。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://elasticsearch.cn/book/elasticsearch_definitive_guide_2.x/index.html" target="_blank" rel="noopener">Elasticsearch: 权威指南</a></li>
<li><a href="https://en.wikipedia.org/wiki/Elasticsearch" target="_blank" rel="noopener">Elasticsearch-维基百科</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 开源技术 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[awk工具介绍]]></title>
      <url>/2017/12/02/awk%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<h3 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h3><p>这是从wikipedia上复制的基本介绍：</p>
<blockquote>
<p>AWK is a programming language designed for text processing and typically used as a data extraction and reporting tool. It is a standard feature of most Unix-like operating systems. </p>
</blockquote>
<p>简单翻译一下，AWK是一种为了文本处理而设计的编程语言，通常作为数据提取和报告工具。它是大多数类Unix操作系统的标准特性。关键词：文本处理  编程语言  工具</p>
<p>本篇文章主要从个人实际工作角度介绍一下awk的常用用法以及相关应用场景，后续我也会保持更新状态，也欢迎主动邮件我，邮件内容格式：场景+示例。</p>
<h3 id="场景和示例"><a href="#场景和示例" class="headerlink" title="场景和示例"></a>场景和示例</h3><p>工作中的日志分析是一个常用的硬技能，而作为类Unix系统下的强大的文本处理程序，awk应该是攻城狮们居家旅游必备良品。</p>
<p>一般的项目日志都会按实际情况进行切割，较多的是按小时切割，比如现在有一个日志文件public.log.2017111101，为了测试方便，我尽可能把日志内容简化了，实际项目中一行日志肯定是比这个要丰富很多的。我模拟了10行日志，日志级别、时间戳、类和方法、日志id、返回数据、耗时，基本接口的返回日志属性都有。</p>
<p><img src="/img/20171202/log2017120201.png" alt=""></p>
<p>首先看一下awk基本格式 <code>awk [options] &#39;program&#39; FILE</code>，经常用linux或者Mac的用户对这个命令格式应该很熟悉，我先不解释了，大家可以百度或者google一下awk的基础知识就行了，而且就算你不知道这个格式，也完全不影响你用它。我个人比较喜欢grep和awk混用来做日志分析，grep用来做日志定位，awk用来做日志分析和格式化输出。</p>
<h4 id="问题1：我需要知道class-classA的所有返回结果"><a href="#问题1：我需要知道class-classA的所有返回结果" class="headerlink" title="问题1：我需要知道class=classA的所有返回结果"></a><em>问题1：我需要知道class=classA的所有返回结果</em></h4><p><code>grep &#39;class=classA&#39; public.log.2017111101</code>这是一个最基础的grep命令，现在我们定位到了class=classA的日志记录</p>
<p><img src="/img/20171202/log2017120202.png" alt=""></p>
<p>但是我们需要的是response结果，这个时候我们就可以用awk很方便的取出来。<br><code>grep &#39;class=classA&#39; public.log.2017111101 | awk -F &#39;\\|\\|&#39; &#39;{print $2}&#39;</code></p>
<p>这个时候需要注意几个点，grep后面接 | 符号我就不说了。awk中我们能看到 -F ，{print $2}这样的元素。F是field的意思，-F是按照某个符号或者字符进行分割，’\|\|’可能有的读者看不懂，是因为|属于特殊字符，在awk中会有一些特殊字符不能直接写在-F中，需要预处理或者转译一下，print是打印，$2是取根据-F分割符分割之后的第二个数据域。可以猜一下这行命令的执行结果。 </p>
<p><img src="/img/20171202/log2017120203.png" alt=""></p>
<p>一般我们打日志的时候为了便于分析，往往会选择json格式，感兴趣的读者可以试试继续把response的内容解析出来。</p>
<h4 id="问题2-我需要知道耗时在33s以上的记录数"><a href="#问题2-我需要知道耗时在33s以上的记录数" class="headerlink" title="问题2: 我需要知道耗时在33s以上的记录数"></a><em>问题2: 我需要知道耗时在33s以上的记录数</em></h4><p>要知道awk是一种编程语言，既然是编程语言，那肯定不止上面那种简单操作吧。</p>
<p><code>cat public.log.2017111101 | awk -F &#39;=&#39; &#39;BEGIN{total=0} {if($NF&gt;33) total++} END{print total}&#39;</code></p>
<p>我们分析一下这个命令，是不是有一种写BASIC和C的感觉。提供BEGIN和END的作用是给程序赋予初始状态和在程序结束之后执行一些扫尾的工作。比如我们在BEGIN中定义了total=0，中间是对每一行的执行逻辑，$NF代表取最后一个数据域（根据=分割之后最后一个数据域当然就是costms的值）,如果耗时大于33ms就执行total++，最后END是打印total值。最终会输出4.</p>
<p><img src="/img/20171202/log2017120204.png" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上就是我在工作中用到的awk的两种最常用的用法，我给出的示例很简单，实际工作中需要根据具体需求和场景做不同的操作，但是总体框架基本不会变。第一种用法可以帮我们很快的做一些简单的数据处理，第二种结合程序设计是可以处理很多复杂的事情，有时候一个命令的长度基本跟得上一个程序代码了。awk里面的具体细节以及其他的用法大家需要多看看文档。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li><a href="https://www.gnu.org/software/gawk/manual/gawk.html#Do-Statement" target="_blank" rel="noopener">awk官方文档</a></li>
<li><a href="http://awk.readthedocs.io/en/latest/index.html#" target="_blank" rel="noopener">awk中文参考</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 工具仓库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[为什么要写博客?]]></title>
      <url>/2017/11/23/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%86%99%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h3 id="为什么要写博客？"><a href="#为什么要写博客？" class="headerlink" title="为什么要写博客？"></a>为什么要写博客？</h3><p><strong>先发一段感慨</strong>：跌跌撞撞，进入职场一年了。回顾过去的一年，从小白到可以独当一面的攻城狮，慢慢开始感觉到自己能做的事情越来越多。</p>
<p>建一个（技术 || 生活）博客的想法在我毕业半年之后就萌芽了。至于为什么要做这个事情，简单总结了一下，可能有以下原因：</p>
<ol>
<li>记录一下成长轨迹，以后和别人吹逼。</li>
<li>平时工作中积累的经验、踩过的坑记录下来</li>
<li>学习、分享、交流</li>
<li>希望它可以成为我的名片，成为我的个人开源平台</li>
</ol>
<h3 id="Hexo-Github"><a href="#Hexo-Github" class="headerlink" title="Hexo+Github"></a>Hexo+Github</h3><p>既然用了Hexo，必须打一波广告。Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p>
<p>我主要看中这三点：简单的命令行操作，丰富的主题，完美支持Github。</p>
<p>GitHub Pages还是很好用的，目前先简单点，把博客放到Github上，说实话大陆访问Github的速度真的无力吐槽，且行且珍惜。</p>
<h3 id="后续的打算"><a href="#后续的打算" class="headerlink" title="后续的打算"></a>后续的打算</h3><p>坚持每周至少写一篇博客，拥抱开源，保持乐观的心态和不断学习的状态。最后，如果我的博客可以帮助到别人那就更加好了。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li><a href="https://pages.github.com/" target="_blank" rel="noopener">Github Pages</a></li>
<li><a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a></li>
<li><a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">Next主题配置</a></li>
<li><a href="http://www.jianshu.com/p/465830080ea9" target="_blank" rel="noopener">Hexo+Github,搭建属于自己的博客</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> 个人感悟 </category>
            
        </categories>
        
        
    </entry>
    
  
  
</search>
